{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49c1989-4815-4bca-9797-0b94f997b014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23604d81-3b60-4a12-8c13-1b9293f845b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    HfArgumentParser, \n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from typing import Dict, Optional\n",
    "from trl import DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b435cf13-4245-44f1-81a0-9a3cfc05ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"gpt2\"\n",
    "ignore_bias_buffers = False\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "if ignore_bias_buffers:\n",
    "    # torch distributed hack\n",
    "    model._ddp_params_and_buffers_to_ignore = [\n",
    "        name for name, buffer in model.named_buffers() if buffer.dtype == torch.bool\n",
    "    ]\n",
    "\n",
    "model_ref = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a03ec-457f-45f4-99a3-3bc3d578532e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340899f0ac3a41e4ba25f03a8ef63f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aa5e924a144bc7bf425ffdfcc14a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c414f0d748d4b75ba017fd27e7833c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SHP dataset\n",
    "dataset = load_dataset(\"stanfordnlp/SHP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315d649e-2ebd-45b7-96c4-d6173006101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'post_id': 'himc90', 'domain': 'askacademia_train', 'upvote_ratio': 0.99, 'history': 'In an interview right before receiving the 2013 Nobel prize in physics, Peter Higgs stated that he wouldn\\'t be able to get an academic job today, because he wouldn\\'t be regarded as productive enough. > By the time he retired in 1996, he was uncomfortable with the new academic culture. \"After I retired it was quite a long time before I went back to my department. I thought I was well out of it. It wasn\\'t my way of doing things any more. Today I wouldn\\'t get an academic job. It\\'s as simple as that. I don\\'t think I would be regarded as productive enough.\"  Another interesting quote from the article is the following:  > He doubts a similar breakthrough could be achieved in today\\'s academic culture, because of the expectations on academics to collaborate and keep churning out papers. He said: \"It\\'s difficult to imagine how I would ever have enough peace and quiet in the present sort of climate to do what I did in 1964.\"  Source (the whole article is pretty interesting): http://theguardian.com/science/2013/dec/06/peter-higgs-boson-academic-system', 'c_root_id_A': 'fwhnqat', 'c_root_id_B': 'fwhp8d4', 'created_at_utc_A': 1593535113, 'created_at_utc_B': 1593535824, 'score_A': 52, 'score_B': 54, 'human_ref_A': 'Currently wrapping up my PhD. There is a stark difference in work balance life between students in my lab who are focused on industry and those focused on academia. The ones in academia feel an immense stress to get high level publications (some staying 8+ years to try to push something into nature/science). The competition has become cut throat. This is a trend not just in America but in Europe, Asia and middle east. International graduate students tell me in China go back 20 years, having any ACS publication from american university is enough to get professorship. Now you better come stacked with publications and at least one nature/science. American universities are even more competitive. How many publications, how many conferences, how many patents...', 'human_ref_B': 'It’s ironic to me that research has shown that productivity isn’t all it’s cracked up to be yet here we are.', 'labels': 0, 'seconds_difference': 711.0, 'score_ratio': 1.0384615385}\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the first example\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857710bf-2297-4d84-a511-cd60cae1d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataSet details\n",
    "#where the fields are:\n",
    "#post_id: the ID of the Reddit post (string)\n",
    "#domain: the subreddit and split the example is drawn from, separated by an underscore (string)\n",
    "#upvote_ratio: the percent of votes received by the post that were positive (aka upvotes) (float)\n",
    "#history: the post title concatented to the post body (string)\n",
    "#c_root_id_A: the ID of comment A (string)\n",
    "#c_root_id_B: the ID of comment B (string)\n",
    "#created_at_utc_A: utc timestamp of when comment A was created (integer)\n",
    "#created_at_utc_B: utc timestamp of when comment B was created (integer)\n",
    "#score_A: (# positive votes - # negative votes + 1) received by comment A (integer)\n",
    "#score_B: (# positive votes - # negative votes + 1) received by comment B (integer)\n",
    "#human_ref_A: text of comment A (string)\n",
    "#human_ref_B: text of comment B (string)\n",
    "#labels: the preference label -- it is 1 if A is preferred to B; 0 if B is preferred to A. \n",
    "#This was randomized such that the label distribution is roughly 50/50. (integer)\n",
    "#seconds_difference: how many seconds after the less preferred comment the more preferred one was created (will always be >= 0) (integer)\n",
    "#score_ratio: the ratio of the more preferred comment's score to the less preferred comment's score (will be >= 1) (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395cb8f2-85e3-4d30-8683-f857e5a49e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the goal is to preprocess the data into the following format:\n",
    "#    \"prompt\": \"The question or context\",\n",
    "#    \"chosen\": \"The preferred response\",\n",
    "#   \"rejected\": \"The non-preferred response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc7c2d6-aa43-46e8-afdd-1d239392f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the prompt i will be using history as it contains the title and body\n",
    "#For the chosen and rejected i will be mapping the label with human_ref_A and human_ref_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee457a2c-b62a-43a0-acaf-acae71415c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset sample: {'prompt': 'In an interview right before receiving the 2013 Nobel prize in physics, Peter Higgs stated that he wouldn\\'t be able to get an academic job today, because he wouldn\\'t be regarded as productive enough. > By the time he retired in 1996, he was uncomfortable with the new academic culture. \"After I retired it was quite a long time before I went back to my department. I thought I was well out of it. It wasn\\'t my way of doing things any more. Today I wouldn\\'t get an academic job. It\\'s as simple as that. I don\\'t think I would be regarded as productive enough.\"  Another interesting quote from the article is the following:  > He doubts a similar breakthrough could be achieved in today\\'s academic culture, because of the expectations on academics to collaborate and keep churning out papers. He said: \"It\\'s difficult to imagine how I would ever have enough peace and quiet in the present sort of climate to do what I did in 1964.\"  Source (the whole article is pretty interesting): http://theguardian.com/science/2013/dec/06/peter-higgs-boson-academic-system', 'chosen': 'It’s ironic to me that research has shown that productivity isn’t all it’s cracked up to be yet here we are.', 'rejected': 'Currently wrapping up my PhD. There is a stark difference in work balance life between students in my lab who are focused on industry and those focused on academia. The ones in academia feel an immense stress to get high level publications (some staying 8+ years to try to push something into nature/science). The competition has become cut throat. This is a trend not just in America but in Europe, Asia and middle east. International graduate students tell me in China go back 20 years, having any ACS publication from american university is enough to get professorship. Now you better come stacked with publications and at least one nature/science. American universities are even more competitive. How many publications, how many conferences, how many patents...'}\n",
      "Tokenized train dataset sample: {'prompt': 'In an interview right before receiving the 2013 Nobel prize in physics, Peter Higgs stated that he wouldn\\'t be able to get an academic job today, because he wouldn\\'t be regarded as productive enough. > By the time he retired in 1996, he was uncomfortable with the new academic culture. \"After I retired it was quite a long time before I went back to my department. I thought I was well out of it. It wasn\\'t my way of doing things any more. Today I wouldn\\'t get an academic job. It\\'s as simple as that. I don\\'t think I would be regarded as productive enough.\"  Another interesting quote from the article is the following:  > He doubts a similar breakthrough could be achieved in today\\'s academic culture, because of the expectations on academics to collaborate and keep churning out papers. He said: \"It\\'s difficult to imagine how I would ever have enough peace and quiet in the present sort of climate to do what I did in 1964.\"  Source (the whole article is pretty interesting): http://theguardian.com/science/2013/dec/06/peter-higgs-boson-academic-system', 'chosen': 'It’s ironic to me that research has shown that productivity isn’t all it’s cracked up to be yet here we are.', 'rejected': 'Currently wrapping up my PhD. There is a stark difference in work balance life between students in my lab who are focused on industry and those focused on academia. The ones in academia feel an immense stress to get high level publications (some staying 8+ years to try to push something into nature/science). The competition has become cut throat. This is a trend not just in America but in Europe, Asia and middle east. International graduate students tell me in China go back 20 years, having any ACS publication from american university is enough to get professorship. Now you better come stacked with publications and at least one nature/science. American universities are even more competitive. How many publications, how many conferences, how many patents...', 'prompt_input_ids': [818, 281, 2720, 826, 878, 6464, 262, 2211, 20715, 11596, 287, 11887, 11, 5613, 367, 20340, 5081, 326, 339, 3636, 470, 307, 1498, 284, 651, 281, 8233, 1693, 1909, 11, 780, 339, 3636, 470, 307, 11987, 355, 12973, 1576, 13, 1875, 2750, 262, 640, 339, 9880, 287, 8235, 11, 339, 373, 12916, 351, 262, 649, 8233, 3968, 13, 366, 3260, 314, 9880, 340, 373, 2407, 257, 890, 640, 878, 314, 1816, 736, 284, 616, 5011, 13, 314, 1807, 314, 373, 880, 503, 286, 340, 13, 632, 2492, 470, 616, 835, 286, 1804, 1243, 597, 517, 13, 6288, 314, 3636, 470, 651, 281, 8233, 1693, 13, 632, 338, 355, 2829, 355, 326, 13, 314, 836, 470, 892, 314, 561, 307, 11987, 355, 12973, 1576, 526, 220, 6023, 3499, 9577], 'prompt_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'chosen_input_ids': [1026, 447, 247, 82, 25304, 284, 502, 326, 2267, 468, 3402, 326, 13714, 2125, 447, 247, 83, 477, 340, 447, 247, 82, 21368, 510, 284, 307, 1865, 994, 356, 389, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'chosen_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'rejected_input_ids': [21327, 27074, 510, 616, 16394, 13, 1318, 318, 257, 19278, 3580, 287, 670, 5236, 1204, 1022, 2444, 287, 616, 2248, 508, 389, 5670, 319, 2831, 290, 883, 5670, 319, 34326, 13, 383, 3392, 287, 34326, 1254, 281, 13964, 5503, 284, 651, 1029, 1241, 16125, 357, 11246, 10589, 807, 10, 812, 284, 1949, 284, 4574, 1223, 656, 3450, 14, 16801, 737, 383, 5449, 468, 1716, 2005, 13589, 13, 770, 318, 257, 5182, 407, 655, 287, 2253, 475, 287, 2031, 11, 7229, 290, 3504, 7627, 13, 4037, 10428, 2444, 1560, 502, 287, 2807, 467, 736, 1160, 812, 11, 1719, 597, 48264, 9207, 422, 45630, 272, 6403, 318, 1576, 284, 651, 2992, 11094, 13, 2735, 345, 1365, 1282, 24167, 351, 16125, 290, 379, 1551, 530, 3450, 14, 16801, 13, 1605, 11155], 'rejected_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Tokenized eval dataset sample: {'prompt': 'Show support for UC academic worker strike Fellow academic community-  Please take a moment to show solidarity with the academic student workers on strike at UC right now.  We are in the second week of the strike by 48,000 academic workers in the University of California (UC) system. The action is the largest strike of academic workers in United States history.  The strikers are demanding a salary increase—from an impossibly low $24,000 a year to $54,000—to address California’s skyrocketing rents and other living expenses.   Sign the letter to President Drake  https://act.aflcio.org/petitions/show-your-support-for-academic-workers-at-university-of-california?source=direct\\\\_link&  Make a donation in the hardship fund if you can  https://givebutter.com/uc-uaw  &#x200B;  https://www.fairucnow.org/support/', 'chosen': 'I was given an offer from UC Davis for their biostatistics program at just $22k flat for the academic year, to which I declined knowing it was ridiculous with that cost of living. I feel for the students who probably felt like they had no choice but to accept, or are first-gens without financial backing from their family.', 'rejected': 'Solidarity with UC academic workers! ✊', 'prompt_input_ids': [15307, 1104, 329, 14417, 8233, 8383, 5587, 29764, 8233, 2055, 12, 220, 4222, 1011, 257, 2589, 284, 905, 17803, 351, 262, 8233, 3710, 3259, 319, 5587, 379, 14417, 826, 783, 13, 220, 775, 389, 287, 262, 1218, 1285, 286, 262, 5587, 416, 4764, 11, 830, 8233, 3259, 287, 262, 2059, 286, 3442, 357, 9598, 8, 1080, 13, 383, 2223, 318, 262, 4387, 5587, 286, 8233, 3259, 287, 1578, 1829, 2106, 13, 220, 383, 45892, 389, 11334, 257, 9588, 2620, 960, 6738, 281, 848, 20846, 1877, 720, 1731, 11, 830, 257, 614, 284, 720, 4051, 11, 830, 960, 1462, 2209, 3442, 447, 247, 82, 6766, 10823, 13629, 28393, 290, 584, 2877, 9307, 13, 220, 220, 5865, 262, 3850, 284, 1992, 18515, 220, 3740, 1378, 529, 13, 1878, 44601, 952], 'prompt_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'chosen_input_ids': [40, 373, 1813, 281, 2897, 422, 14417, 7802, 329, 511, 3182, 455, 265, 3969, 1430, 379, 655, 720, 1828, 74, 6228, 329, 262, 8233, 614, 11, 284, 543, 314, 7392, 6970, 340, 373, 11441, 351, 326, 1575, 286, 2877, 13, 314, 1254, 329, 262, 2444, 508, 2192, 2936, 588, 484, 550, 645, 3572, 475, 284, 2453, 11, 393, 389, 717, 12, 70, 641, 1231, 3176, 12285, 422, 511, 1641, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'chosen_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'rejected_input_ids': [46933, 6806, 351, 14417, 8233, 3259, 0, 14519, 232, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'rejected_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "# Preprocessing function\n",
    "def preprocess_shp_dataset(sample):\n",
    "    prompt = sample[\"history\"]\n",
    "    if sample[\"labels\"] == 1:\n",
    "        chosen = sample[\"human_ref_A\"]\n",
    "        rejected = sample[\"human_ref_B\"]\n",
    "    else:\n",
    "        chosen = sample[\"human_ref_B\"]\n",
    "        rejected = sample[\"human_ref_A\"]\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "    }\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(preprocess_shp_dataset)\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = [\n",
    "    \"post_id\", \"domain\", \"upvote_ratio\", \"c_root_id_A\", \"c_root_id_B\",\n",
    "    \"created_at_utc_A\", \"created_at_utc_B\", \"score_A\", \"score_B\",\n",
    "    \"human_ref_A\", \"human_ref_B\", \"labels\", \"seconds_difference\", \"score_ratio\",\n",
    "    \"history\"  # Explicitly remove the 'history' field\n",
    "]\n",
    "\n",
    "# Remove unnecessary columns\n",
    "dataset = dataset.remove_columns(columns_to_remove)\n",
    "\n",
    "# Inspect a sample from the preprocessed dataset\n",
    "print(\"Preprocessed dataset sample:\", dataset[\"train\"][0])\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(batch):\n",
    "    # Tokenize the prompt, chosen, and rejected texts\n",
    "    prompt_encodings = tokenizer(\n",
    "        batch[\"prompt\"], truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "    chosen_encodings = tokenizer(\n",
    "        batch[\"chosen\"], truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "    rejected_encodings = tokenizer(\n",
    "        batch[\"rejected\"], truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "    \n",
    "    # Return only the tokenized outputs (no raw text)\n",
    "    return {\n",
    "        \"prompt_input_ids\": prompt_encodings[\"input_ids\"],\n",
    "        \"prompt_attention_mask\": prompt_encodings[\"attention_mask\"],\n",
    "        \"chosen_input_ids\": chosen_encodings[\"input_ids\"],\n",
    "        \"chosen_attention_mask\": chosen_encodings[\"attention_mask\"],\n",
    "        \"rejected_input_ids\": rejected_encodings[\"input_ids\"],\n",
    "        \"rejected_attention_mask\": rejected_encodings[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "train_dataset = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "eval_dataset = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "\n",
    "# Verify the tokenized dataset\n",
    "print(\"Tokenized train dataset sample:\", train_dataset[0])\n",
    "print(\"Tokenized eval dataset sample:\", eval_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91dda53-aaba-4320-91ee-d8e26ddcb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 348718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 18436\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 18409\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5614e741-ee87-473e-9dcc-de02fe59ec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'prompt_input_ids', 'prompt_attention_mask', 'chosen_input_ids', 'chosen_attention_mask', 'rejected_input_ids', 'rejected_attention_mask'],\n",
       "    num_rows: 348718\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84af19bb-df8a-404b-8e6a-918f54cb3e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68e31d5065446739586229f0d395069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/348718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455e43cf0e784d2da12a7b27fbae8a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DPOTrainer, DPOConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set a padding token if not already defined\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define maximum sequence length\n",
    "max_length = 1024\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    prompt_encodings = tokenizer(examples[\"prompt\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    chosen_encodings = tokenizer(examples[\"chosen\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    rejected_encodings = tokenizer(examples[\"rejected\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    return {\n",
    "        \"prompt_input_ids\": prompt_encodings[\"input_ids\"],\n",
    "        \"prompt_attention_mask\": prompt_encodings[\"attention_mask\"],\n",
    "        \"chosen_input_ids\": chosen_encodings[\"input_ids\"],\n",
    "        \"chosen_attention_mask\": chosen_encodings[\"attention_mask\"],\n",
    "        \"rejected_input_ids\": rejected_encodings[\"input_ids\"],\n",
    "        \"rejected_attention_mask\": rejected_encodings[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, batch_size=1000)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae5b6bb9-6326-4a70-aaf2-ef363f4d1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'learning_rate': 1e-05, 'gradient_accumulation_steps': 4, 'beta': 0.1, 'num_train_epochs': 3, 'loss_type': 'sigmoid'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e31ebf03c3c42d39538170ffc4f65d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/348718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0566bcb46db4ff9b6b25fd5ca0a4388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/348718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4939dbc58fe54d04b94acebd891e6cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/348718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4143ee810c9f4bdaa979d5ea3bf5793e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in eval dataset:   0%|          | 0/18409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501a62f304204c2e9ad6a77349a306a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/18409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291eb53208524a01b92e7d812302d96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/18409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 34:04, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.657300</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.334662</td>\n",
       "      <td>0.051408</td>\n",
       "      <td>0.617832</td>\n",
       "      <td>0.283254</td>\n",
       "      <td>-455.476532</td>\n",
       "      <td>-297.744812</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.635729</td>\n",
       "      <td>0.374762</td>\n",
       "      <td>0.055464</td>\n",
       "      <td>0.624729</td>\n",
       "      <td>0.319298</td>\n",
       "      <td>-455.075500</td>\n",
       "      <td>-297.704285</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2302' max='2302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2302/2302 11:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics are missing. Computing manually...\n",
      "Model, tokenizer, and training artifacts saved to ./dpo_model_1e-05_0.1\n",
      "Training with hyperparameters: {'learning_rate': 0.0001, 'gradient_accumulation_steps': 4, 'beta': 0.5, 'num_train_epochs': 5, 'loss_type': 'hinge'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea79bec3a9040c5bfc33741128a7043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/348718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0bb153549c4bfe933188d28607b956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/348718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 35:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.665500</td>\n",
       "      <td>3.802597</td>\n",
       "      <td>-9.335428</td>\n",
       "      <td>-9.425274</td>\n",
       "      <td>0.491366</td>\n",
       "      <td>0.089845</td>\n",
       "      <td>-477.493958</td>\n",
       "      <td>-317.109406</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.641600</td>\n",
       "      <td>2.326569</td>\n",
       "      <td>-5.125587</td>\n",
       "      <td>-6.470866</td>\n",
       "      <td>0.556907</td>\n",
       "      <td>1.345279</td>\n",
       "      <td>-469.074341</td>\n",
       "      <td>-311.200623</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2302' max='2302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2302/2302 11:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics are missing. Computing manually...\n",
      "Model, tokenizer, and training artifacts saved to ./dpo_model_0.0001_0.5\n",
      "Training with hyperparameters: {'learning_rate': 0.001, 'gradient_accumulation_steps': 4, 'beta': 1.0, 'num_train_epochs': 1, 'loss_type': 'sigmoid'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 33:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>57.875800</td>\n",
       "      <td>68.257011</td>\n",
       "      <td>-187.568954</td>\n",
       "      <td>-147.685074</td>\n",
       "      <td>0.411273</td>\n",
       "      <td>-39.883907</td>\n",
       "      <td>-646.392090</td>\n",
       "      <td>-445.943909</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>31.029900</td>\n",
       "      <td>33.313473</td>\n",
       "      <td>-219.706558</td>\n",
       "      <td>-209.438049</td>\n",
       "      <td>0.490226</td>\n",
       "      <td>-10.268484</td>\n",
       "      <td>-678.529724</td>\n",
       "      <td>-507.696991</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2302' max='2302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2302/2302 11:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics are missing. Computing manually...\n",
      "Model, tokenizer, and training artifacts saved to ./dpo_model_0.001_1.0\n",
      "\n",
      "Experiment Results:\n",
      "Hyperparameters: {'learning_rate': 1e-05, 'gradient_accumulation_steps': 4, 'beta': 0.1, 'num_train_epochs': 3, 'loss_type': 'sigmoid'}\n",
      "Training Loss: 0.6360240335464478\n",
      "Evaluation Loss: 0.6357294321060181\n",
      "Rewards/Chosen: None\n",
      "Rewards/Rejected: None\n",
      "Rewards/Accuracies: None\n",
      "Rewards/Margins: None\n",
      "Logps/Chosen: None\n",
      "Logps/Rejected: None\n",
      "--------------------------------------------------\n",
      "Hyperparameters: {'learning_rate': 0.0001, 'gradient_accumulation_steps': 4, 'beta': 0.5, 'num_train_epochs': 5, 'loss_type': 'hinge'}\n",
      "Training Loss: 2.601649865150452\n",
      "Evaluation Loss: 2.3265693187713623\n",
      "Rewards/Chosen: None\n",
      "Rewards/Rejected: None\n",
      "Rewards/Accuracies: None\n",
      "Rewards/Margins: None\n",
      "Logps/Chosen: None\n",
      "Logps/Rejected: None\n",
      "--------------------------------------------------\n",
      "Hyperparameters: {'learning_rate': 0.001, 'gradient_accumulation_steps': 4, 'beta': 1.0, 'num_train_epochs': 1, 'loss_type': 'sigmoid'}\n",
      "Training Loss: 64.18204498291016\n",
      "Evaluation Loss: 33.313472747802734\n",
      "Rewards/Chosen: None\n",
      "Rewards/Rejected: None\n",
      "Rewards/Accuracies: None\n",
      "Rewards/Margins: None\n",
      "Logps/Chosen: None\n",
      "Logps/Rejected: None\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from trl import DPOTrainer, DPOConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define hyperparameter combinations (batch size fixed at 4)\n",
    "hyperparameter_combinations = [\n",
    "    {\"learning_rate\": 1e-5, \"gradient_accumulation_steps\": 4, \"beta\": 0.1, \"num_train_epochs\": 3, \"loss_type\": \"sigmoid\"},\n",
    "    {\"learning_rate\": 1e-4, \"gradient_accumulation_steps\": 4, \"beta\": 0.5, \"num_train_epochs\": 5, \"loss_type\": \"hinge\"},\n",
    "    {\"learning_rate\": 1e-3, \"gradient_accumulation_steps\": 4, \"beta\": 1.0, \"num_train_epochs\": 1, \"loss_type\": \"sigmoid\"},\n",
    "]\n",
    "\n",
    "# Experiment with hyperparameters\n",
    "results = []\n",
    "for params in hyperparameter_combinations:\n",
    "    print(f\"Training with hyperparameters: {params}\")\n",
    "    \n",
    "    # Update DPOConfig\n",
    "    dpo_config = DPOConfig(\n",
    "        output_dir=f\"./dpo_model_{params['learning_rate']}_{params['beta']}\",  # Unique output directory\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        per_device_train_batch_size=2,  # Fixed batch size\n",
    "        gradient_accumulation_steps=params[\"gradient_accumulation_steps\"],\n",
    "        max_steps=1000,\n",
    "        num_train_epochs=params[\"num_train_epochs\"],\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_total_limit=2,\n",
    "        fp16=True,  # Mixed precision training\n",
    "        gradient_checkpointing=True,  # Gradient checkpointing\n",
    "        report_to=None,\n",
    "        beta=params[\"beta\"],\n",
    "        loss_type=params[\"loss_type\"],\n",
    "        padding_value=tokenizer.pad_token_id,\n",
    "    )\n",
    "    \n",
    "    # Initialize DPOTrainer\n",
    "    dpo_trainer = DPOTrainer(\n",
    "        model=model,\n",
    "        ref_model=ref_model,\n",
    "        args=dpo_config,  # Use DPOConfig instead of TrainingArguments\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        processing_class=tokenizer,  # Use `processing_class` instead of `tokenizer`\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    train_result = dpo_trainer.train()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    eval_result = dpo_trainer.evaluate()\n",
    "    \n",
    "    # Check if evaluation metrics are present\n",
    "    if \"rewards/chosen\" not in eval_result:\n",
    "        print(\"Evaluation metrics are missing. Computing manually...\")\n",
    "        # Manually compute evaluation metrics\n",
    "        eval_result = {\n",
    "            \"eval_loss\": eval_result.get(\"eval_loss\", None),\n",
    "            \"rewards/chosen\": None,\n",
    "            \"rewards/rejected\": None,\n",
    "            \"rewards/accuracies\": None,\n",
    "            \"rewards/margins\": None,\n",
    "            \"logps/chosen\": None,\n",
    "            \"logps/rejected\": None,\n",
    "        }\n",
    "    \n",
    "    # Record results\n",
    "    results.append({\n",
    "        \"hyperparameters\": params,\n",
    "        \"train_loss\": train_result.training_loss,\n",
    "        \"eval_loss\": eval_result[\"eval_loss\"],\n",
    "        \"rewards_chosen\": eval_result[\"rewards/chosen\"],\n",
    "        \"rewards_rejected\": eval_result[\"rewards/rejected\"],\n",
    "        \"rewards_accuracies\": eval_result[\"rewards/accuracies\"],\n",
    "        \"rewards_margins\": eval_result[\"rewards/margins\"],\n",
    "        \"logps_chosen\": eval_result[\"logps/chosen\"],\n",
    "        \"logps_rejected\": eval_result[\"logps/rejected\"],\n",
    "    })\n",
    "    \n",
    "    # Save the model and tokenizer\n",
    "    model.save_pretrained(dpo_config.output_dir)\n",
    "    tokenizer.save_pretrained(dpo_config.output_dir)\n",
    "    \n",
    "    # Save the trainer state\n",
    "    dpo_trainer.save_model(dpo_config.output_dir)\n",
    "    \n",
    "    # Save training metrics\n",
    "    metrics = {\n",
    "        \"train_loss\": train_result.training_loss,\n",
    "        \"eval_loss\": eval_result[\"eval_loss\"],\n",
    "        \"rewards_chosen\": eval_result[\"rewards/chosen\"],\n",
    "        \"rewards_rejected\": eval_result[\"rewards/rejected\"],\n",
    "        \"rewards_accuracies\": eval_result[\"rewards/accuracies\"],\n",
    "        \"rewards_margins\": eval_result[\"rewards/margins\"],\n",
    "        \"logps_chosen\": eval_result[\"logps/chosen\"],\n",
    "        \"logps_rejected\": eval_result[\"logps/rejected\"],\n",
    "    }\n",
    "    \n",
    "    with open(f\"{dpo_config.output_dir}/training_metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    # Save hyperparameters\n",
    "    hyperparameters = {\n",
    "        \"learning_rate\": dpo_config.learning_rate,\n",
    "        \"batch_size\": dpo_config.per_device_train_batch_size,\n",
    "        \"gradient_accumulation_steps\": dpo_config.gradient_accumulation_steps,\n",
    "        \"beta\": dpo_config.beta,\n",
    "        \"num_train_epochs\": dpo_config.num_train_epochs,\n",
    "        \"loss_type\": dpo_config.loss_type,\n",
    "    }\n",
    "    \n",
    "    with open(f\"{dpo_config.output_dir}/hyperparameters.json\", \"w\") as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    \n",
    "    print(f\"Model, tokenizer, and training artifacts saved to {dpo_config.output_dir}\")\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nExperiment Results:\")\n",
    "for result in results:\n",
    "    print(f\"Hyperparameters: {result['hyperparameters']}\")\n",
    "    print(f\"Training Loss: {result['train_loss']}\")\n",
    "    print(f\"Evaluation Loss: {result['eval_loss']}\")\n",
    "    print(f\"Rewards/Chosen: {result['rewards_chosen']}\")\n",
    "    print(f\"Rewards/Rejected: {result['rewards_rejected']}\")\n",
    "    print(f\"Rewards/Accuracies: {result['rewards_accuracies']}\")\n",
    "    print(f\"Rewards/Margins: {result['rewards_margins']}\")\n",
    "    print(f\"Logps/Chosen: {result['logps_chosen']}\")\n",
    "    print(f\"Logps/Rejected: {result['logps_rejected']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e6327-cf1b-48b4-8c61-0e3c5fe896dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pushing best combination on hugging face. that is hyper parameter lr: 1e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
